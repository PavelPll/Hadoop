from here: https://sparkbyexamples.com/apache-hive/apache-hive-installation-on-hadoop/
(1)ssh datanode3
apt update
apt-get install

(2)wget https://apache.osuosl.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz
tar -xzf apache-hive-3.1.2-bin.tar.gz
mv apache-hive-3.1.2-bin hive

(3)nano ~/.bashrc
export YARN_HOME=${HADOOP_HOME}
#Hive configurations
export HIVE_HOME=/home/ubuntu/hive
export PATH=$PATH:$HIVE_HOME/sbin:$HIVE_HOME/bin
export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib/*:$HIVE_HOME/lib/*
source ~/.bashrc

(4)cp $HIVE_HOME/conf/hive-default.xml.template $HIVE_HOME/conf/hive-site.xml
nano $HIVE_HOME/conf/hive-site.xml
hive.server2.active.passive.ha.enable false to true
(5)Replace all occurrences of ${system:java.io.tmpdir} to /tmp/hive
cat $HIVE_HOME/conf/hive-site.xml | grep -F '${system:java.io.tmpdir}'
(6)Replace all occurrences of ${system:user.name} to username, the username should be the one you log in with.
cat $HIVE_HOME/conf/hive-site.xml | grep -F '${system:user.name}'
(7)Add to the end:
<property>
    <name>hive.exec.local.scratchdir</name>
    <value>/tmp/ubuntu</value>
    <description>Local scratch space for Hive jobs</description>
  </property>

  <property>
    <name>hive.downloaded.resources.dir</name>
    <value>/tmp/${hive.session.id}_resources</value>
    <description>Temporary local directory for added resources in the remote file system.</description>
  </property>


(8) do not touch if you are the only user of hive
Hive Metastore database
I will be using default embedded Derby Metastore, in case if you wanted to use MySQL or 
any other RDBMS database, change the below configurations accordingly.
<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:derby:;databaseName=metastore_db;create=true</value>
    <description>
      JDBC connect string for a JDBC metastore.
      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
    </description>
</property>

(9)CREATE folder for databases
hdfs dfs -mkdir /user/hive/warehouse
hdfs dfs -mkdir /user/tmp
hdfs dfs -chmod g+w /user/tmp
hdfs dfs -chmod g+w /user/hive/warehouse

(10)Post Apache Hive Installation, before you start using Hive, you need to initialize the Metastore database with the database 
type you choose. By default Hive uses the Derby database, you can also choose any RDBS database for Metastore
$HIVE_HOME/bin/schematool -initSchema -dbType derby
(11)
hive
or if you want to work from remote server start this:
beeline -u jdbc:hive2:// -n scott -p tiger
-------------------end-------------------

